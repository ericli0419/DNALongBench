{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678ea7e2-5826-4206-b69c-806578c3ed3b",
   "metadata": {},
   "source": [
    "This notebook contains example code to load data from DNALongBench. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4412845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/work/magroup/shared/DNA_LLM/DNALongBench/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3d4bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 04:15:10.707744: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-18 04:15:10.779738: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-18 04:15:12.795664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/wenduoc/mambaforge/envs/dnalongbench2/lib/python3.9/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100000, 4]) torch.Size([16, 10, 100000])\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126aec72",
   "metadata": {},
   "source": [
    "# Regulatory Sequence Activity Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c53c15",
   "metadata": {},
   "source": [
    "This task has two subsets: \"human\" and \"mouse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58222359",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = load_data(root=root, task_name = 'regulatory_sequence_activity', organism = 'human', cell_type=None, batch_size=16, sequence_length=196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a91347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 04:15:23.429798: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-11-18 04:15:23.628765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [133]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-11-18 04:15:23.629080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [133]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([16, 196608, 4])\n",
      "y: torch.Size([16, 896, 5313])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenduoc/mambaforge/envs/dnalongbench2/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:171: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader: \n",
    "        x, y = batch\n",
    "        print('x:',x.size())\n",
    "        print('y:',y.size())\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c64c1",
   "metadata": {},
   "source": [
    "# Contact Map Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b421d",
   "metadata": {},
   "source": [
    "This task has five cell types: 'HFF', 'H1hESC', 'GM12878', 'IMR90', 'HCT116'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69c5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = load_data(root=root, task_name = 'contact_map_prediction', organism = None, cell_type='HFF', batch_size=16, sequence_length=196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca37ee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 04:15:30.952569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [28]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([16, 1048576, 4])\n",
      "y: torch.Size([16, 99681])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader: \n",
    "        x, y = batch\n",
    "        print('x:',x.size())\n",
    "        print('y:',y.size())\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77691c35",
   "metadata": {},
   "source": [
    "# Transcription Initiation Signal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18682c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, _, _ = load_data(root=root, task_name = 'transcription_initiation_signal_prediction', organism = 'None', cell_type='None', batch_size=16, sequence_length=196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab69aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([16, 100000, 4])\n",
      "y: torch.Size([16, 10, 100000])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader: \n",
    "        x, y = batch\n",
    "        print('x:',x.size())\n",
    "        print('y:',y.size())\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf504828-e707-41ed-85bc-667e95ba3cd3",
   "metadata": {},
   "source": [
    "# Enhancer target gene prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81962f0f-7f94-40a7-9d3b-0dc92c02f552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> load config done\n",
      "> init fasta extractor done\n",
      "> Start parsing EPI records to build the dataset train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2602/2602 [00:36<00:00, 70.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Finish parsing EPI records\n",
      "# Total records:  2602\n",
      "# Skipped records due to different chromosomes:  0\n",
      "# Skipped records due to distance cutoff:  0\n",
      "# Skipped records due to unknown strand:  0\n",
      "# Select records 2066 with subset train \n",
      "> load config done\n",
      "> init fasta extractor done\n",
      "> Start parsing EPI records to build the dataset valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2602/2602 [00:05<00:00, 500.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Finish parsing EPI records\n",
      "# Total records:  2602\n",
      "# Skipped records due to different chromosomes:  0\n",
      "# Skipped records due to distance cutoff:  0\n",
      "# Skipped records due to unknown strand:  0\n",
      "# Select records 266 with subset valid \n",
      "> load config done\n",
      "> init fasta extractor done\n",
      "> Start parsing EPI records to build the dataset test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2602/2602 [00:04<00:00, 575.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Finish parsing EPI records\n",
      "# Total records:  2602\n",
      "# Skipped records due to different chromosomes:  0\n",
      "# Skipped records due to distance cutoff:  0\n",
      "# Skipped records due to unknown strand:  0\n",
      "# Select records 270 with subset test \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = load_data(root = root, task_name = 'enhancer_target_gene_prediction', organism = None, cell_type = None, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1942bb31-0dcd-4bf7-a08f-745a1a62e58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([16, 4500000, 4])\n",
      "y: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader: \n",
    "        x, y = batch\n",
    "        print('x:',x.size())\n",
    "        print('y:',y.size())\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52796588-c496-4eb7-bde0-b76cabe16e26",
   "metadata": {},
   "source": [
    "# eQTL prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f0b73-df02-422f-874f-c8cc1002ebd5",
   "metadata": {},
   "source": [
    "This task has nine cell types: 'Adipose_Subcutaneous', 'Artery_Tibial', 'Cells_Cultured_fibroblasts', 'Muscle_Skeletal', 'Nerve_Tibial', 'Skin_Not_Sun_Exposed_Suprapubic', 'Skin_Sun_Exposed_Lower_leg', 'Thyroid', 'Whole_Blood'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc1b10e1-b8fc-47a4-8635-0ad1ae9f14a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> load config done\n",
      "> init fasta extractor done\n",
      "> Start parsing eQTL records to build the dataset train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2181/2181 [00:41<00:00, 52.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Finish parsing eQTL records\n",
      "# Total records:  2181\n",
      "# Skipped records due to different chromosomes:  0\n",
      "# Skipped records due to distance cutoff:  0\n",
      "# Skipped records due to unknown strand:  0\n",
      "# Select records 1280 with subset train \n",
      "> load config done\n",
      "> init fasta extractor done\n",
      "> Start parsing eQTL records to build the dataset valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2181/2181 [00:16<00:00, 134.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Finish parsing eQTL records\n",
      "# Total records:  2181\n",
      "# Skipped records due to different chromosomes:  0\n",
      "# Skipped records due to distance cutoff:  0\n",
      "# Skipped records due to unknown strand:  0\n",
      "# Select records 566 with subset valid \n",
      "> load config done\n",
      "> init fasta extractor done\n",
      "> Start parsing eQTL records to build the dataset test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2181/2181 [00:10<00:00, 215.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Finish parsing eQTL records\n",
      "# Total records:  2181\n",
      "# Skipped records due to different chromosomes:  0\n",
      "# Skipped records due to distance cutoff:  0\n",
      "# Skipped records due to unknown strand:  0\n",
      "# Select records 335 with subset test \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = load_data(root = root, task_name = 'eqtl_prediction', organism = None, cell_type = 'Adipose_Subcutaneous', batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96441ff8-67eb-47fc-a4b9-18f5ff7aa934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_ref: torch.Size([16, 4500000, 4])\n",
      "x_alt torch.Size([16, 4500000, 4])\n",
      "y: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader: \n",
    "        print('x_ref:', batch['x_ref'].size())\n",
    "        print('x_alt', batch['x_alt'].size())\n",
    "        print('y:',batch['y'].size())\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
