{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a62f08-017d-4f15-a8a2-b85daa6e9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40c98a9-5ed9-4918-90f0-68262bb9ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenduoc/mambaforge/envs/enformer/lib/python3.8/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tabix\n",
    "import torch\n",
    "import selene_sdk\n",
    "import pyBigWig\n",
    "from torch import nn\n",
    "from scipy.special import softmax\n",
    "from matplotlib import pyplot as plt\n",
    "from selene_sdk.targets import Target\n",
    "from selene_sdk.samplers import RandomPositionsSampler\n",
    "from selene_sdk.samplers.dataloader import SamplerDataLoader\n",
    "from scipy.stats import spearmanr\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233db8a4-1908-483b-b48d-342fb83921b3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aeaa917-fd71-4951-8352-47e2b7746674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selene_sdk\n",
    "\n",
    "root = \"/work/magroup/4DN/Puffin/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4a6fef-3669-43ff-a85c-fe6d9ac4e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = selene_sdk.sequences.Genome(\n",
    "                    input_path=root+\"Homo_sapiens.GRCh38.dna.primary_assembly.fa\",\n",
    "                    blacklist_regions= 'hg38'\n",
    "                )\n",
    "\n",
    "noblacklist_genome = selene_sdk.sequences.Genome(\n",
    "                    input_path=root+\"Homo_sapiens.GRCh38.dna.primary_assembly.fa\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d66320-3d4b-4715-bea0-5e255a06272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyBigWig\n",
    "import tabix\n",
    "from selene_sdk.targets import Target\n",
    "import numpy as np\n",
    "\n",
    "class GenomicSignalFeatures(Target):\n",
    "    \"\"\"\n",
    "    #Accept a list of cooler files as input.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_paths, features, shape, blacklists=None, blacklists_indices=None, \n",
    "        replacement_indices=None, replacement_scaling_factors=None):\n",
    "        \"\"\"\n",
    "        Constructs a new `GenomicFeatures` object.\n",
    "        \"\"\"\n",
    "        self.input_paths = input_paths\n",
    "        self.initialized = False\n",
    "        self.blacklists = blacklists\n",
    "        self.blacklists_indices = blacklists_indices\n",
    "        self.replacement_indices = replacement_indices\n",
    "        self.replacement_scaling_factors = replacement_scaling_factors\n",
    "\n",
    "            \n",
    "        self.n_features = len(features)\n",
    "        self.feature_index_dict = dict(\n",
    "            [(feat, index) for index, feat in enumerate(features)])\n",
    "        self.shape = (len(input_paths), *shape)\n",
    "\n",
    "    def get_feature_data(self, chrom, start, end, nan_as_zero=True, feature_indices=None):\n",
    "        if not self.initialized:\n",
    "            self.data = [pyBigWig.open(path) for path in self.input_paths]\n",
    "            if self.blacklists is not None:\n",
    "                self.blacklists = [tabix.open(blacklist)  for blacklist in self.blacklists]\n",
    "            self.initialized=True\n",
    "\n",
    "        if feature_indices is None:\n",
    "            feature_indices = np.arange(len(self.data))\n",
    "\n",
    "        wigmat = np.zeros((len(feature_indices), end - start), dtype=np.float32)\n",
    "        for i in feature_indices:\n",
    "            try:\n",
    "                wigmat[i, :] = self.data[i].values(chrom, start, end, numpy=True)\n",
    "            except:\n",
    "                print(chrom, start, end, self.input_paths[i], flush=True)\n",
    "                raise\n",
    "        \n",
    "        if self.blacklists is not None:\n",
    "            if self.replacement_indices is None:\n",
    "                if self.blacklists_indices is not None:\n",
    "                    for blacklist, blacklist_indices in zip(self.blacklists, self.blacklists_indices):\n",
    "                        for _, s, e in blacklist.query(chrom, start, end):\n",
    "                            wigmat[blacklist_indices, np.fmax(int(s)-start,0): int(e)-start] = 0\n",
    "                else:\n",
    "                    for blacklist in self.blacklists:\n",
    "                        for _, s, e in blacklist.query(chrom, start, end):\n",
    "                            wigmat[:, np.fmax(int(s)-start,0): int(e)-start] = 0\n",
    "            else:\n",
    "                for blacklist, blacklist_indices, replacement_indices, replacement_scaling_factor in zip(self.blacklists, self.blacklists_indices, self.replacement_indices, self.replacement_scaling_factors):\n",
    "                    for _, s, e in blacklist.query(chrom, start, end):\n",
    "                        wigmat[blacklist_indices, np.fmax(int(s)-start,0): int(e)-start] = wigmat[replacement_indices, np.fmax(int(s)-start,0): int(e)-start] * replacement_scaling_factor\n",
    "\n",
    "        if nan_as_zero:\n",
    "            wigmat[np.isnan(wigmat)]=0\n",
    "        return wigmat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tfeature = GenomicSignalFeatures([root+\"agg.plus.bw.bedgraph.bw\",\n",
    "root+\"agg.encodecage.plus.v2.bedgraph.bw\",\n",
    "root+\"agg.encoderampage.plus.v2.bedgraph.bw\",\n",
    "root+\"agg.plus.grocap.bedgraph.sorted.merged.bw\",\n",
    "root+\"agg.plus.allprocap.bedgraph.sorted.merged.bw\",\n",
    "root+\"agg.minus.allprocap.bedgraph.sorted.merged.bw\",\n",
    "root+\"agg.minus.grocap.bedgraph.sorted.merged.bw\",\n",
    "root+\"agg.encoderampage.minus.v2.bedgraph.bw\",\n",
    "root+\"agg.encodecage.minus.v2.bedgraph.bw\",\n",
    "root+\"agg.minus.bw.bedgraph.bw\"],\n",
    "                               ['cage_plus','encodecage_plus','encoderampage_plus', 'grocap_plus','procap_plus','procap_minus','grocap_minus'\n",
    ",'encoderampage_minus', 'encodecage_minus',\n",
    "'cage_minus'],\n",
    "                               (100000,),\n",
    "                               [root+\"fantom.blacklist8.plus.bed.gz\",root+\"fantom.blacklist8.minus.bed.gz\"],\n",
    "                               [0,9], [1,8], [0.61357, 0.61357])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7827975a-404c-4561-bf92-7ca049a7b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomPositionsSampler(\n",
    "                reference_sequence= genome,\n",
    "                target= tfeature,\n",
    "                features = [''],\n",
    "                test_holdout=['chr8', 'chr9'],\n",
    "                validation_holdout= ['chr10'],\n",
    "                sequence_length= 100000,\n",
    "                center_bin_to_predict= 100000,\n",
    "                position_resolution=1,\n",
    "                random_shift=0,\n",
    "                random_strand=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "048303d9-cd62-4975-8a01-a8e94416ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=3\n",
    "\n",
    "# Train loader\n",
    "sampler.mode=\"train\"\n",
    "# train_loader = SamplerDataLoader(sampler, num_workers=32, batch_size=32, seed=seed)\n",
    "train_loader = SamplerDataLoader(sampler, num_workers=1, batch_size=16, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0715d4-8e56-4dd6-ac27-a041c6919adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 100000, 4]) torch.Size([16, 10, 100000])\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for sequence, target in train_loader:\n",
    "    print(sequence.shape,target.shape)\n",
    "    print(sequence[0,:3,:])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1bd0b7-5a90-4993-a8ef-a65946945426",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52be1f63-0b5f-4599-b191-076a78715d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# Define the CNN\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv1d(in_channels=32, out_channels=10, kernel_size=3, padding=1)\n",
    "#         self.relu = nn.ReLU()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.conv1(x))\n",
    "#         x = self.relu(self.conv2(x))\n",
    "#         x = self.conv3(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cbef02b-6ec4-40db-929e-dc5d208ee769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=in_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              dilation=dilation,\n",
    "                              padding=(kernel_size - 1) * dilation,\n",
    "                              stride=stride),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.BatchNorm1d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels=4, channels = [16,32,64], output_shape=2, input_length=450000, dropout_rate=0, kernel_sizes = None, dilation_sizes = None):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        kernel_sizes = [3 for i in range(len(channels))] if kernel_sizes is None else kernel_sizes\n",
    "        dilation_sizes = [1 for i in range(len(channels))] if dilation_sizes is None else dilation_sizes \n",
    "\n",
    "        layers = [ConvBlock(in_channels=in_channels, out_channels=channels[0], kernel_size=kernel_sizes[0], stride=1, dilation=dilation_sizes[0], dropout_rate=dropout_rate)]\n",
    "        self.output_shape = output_shape\n",
    "        self.input_length = input_length\n",
    "        \n",
    "        for i in range(len(channels) - 1):\n",
    "            in_channels = channels[i]\n",
    "            out_channels = channels[i + 1]\n",
    "            layers.append(ConvBlock(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_sizes[i+1], stride=1, dilation=dilation_sizes[i+1], dropout_rate=dropout_rate))\n",
    "  \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        if isinstance(output_shape, int):  # ETGP, eQTLP\n",
    "            self.fout = 'Linear'\n",
    "            self.fc = nn.Linear(channels[-1], output_shape)\n",
    "            self.relu = nn.ReLU()\n",
    "        elif len(output_shape)==2:  # RSAP, TISP\n",
    "            self.fout = 'Conv1d'\n",
    "            self.adaptive_pool = nn.AdaptiveMaxPool1d(output_shape[0])  # Adaptive pooling to ensure the exact sequence length\n",
    "            self.final_conv = nn.Conv1d(channels[-1], output_shape[1], kernel_size=1)  # Adjust channels without changing length\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  \n",
    "        x = self.layers(x)\n",
    "        if self.fout == 'Linear':\n",
    "            x = F.max_pool1d(x, x.size(2)).squeeze()\n",
    "            x = self.fc(x)\n",
    "            x = self.relu(x)\n",
    "        elif self.fout == 'Conv1d': \n",
    "            x = self.adaptive_pool(x)\n",
    "            x = self.final_conv(x)\n",
    "            x = x.transpose(1, 2) \n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eaf1f61-c97f-47d4-9a20-c604a6ccffbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (layers): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv1d(4, 16, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (1): Dropout(p=0, inplace=False)\n",
       "        (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (1): Dropout(p=0, inplace=False)\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (1): Dropout(p=0, inplace=False)\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (3): ConvBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (1): Dropout(p=0, inplace=False)\n",
       "        (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveMaxPool1d(output_size=100000)\n",
       "  (final_conv): Conv1d(1024, 10, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleCNN(channels = [16,64,256,1024], output_shape=(100000,10), input_length=100000)\n",
    "model.cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632df342-ab25-435e-941f-3d1c0aee0744",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36fe4983-bad5-4b39-bc6d-2d96121a0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "def PseudoPoissonKL(lpred, ltarget):\n",
    "    return (ltarget * torch.log((ltarget+1e-10)/(lpred+1e-10)) + lpred - ltarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a3643d5-2eab-4a8d-898c-bf1ba88de7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss and optimizer\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.MSELoss()\n",
    "# weights = torch.ones(10).cuda()\n",
    "# criterion = PseudoPoissonKL\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.005)\n",
    "\n",
    "# Define scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.9, patience=10, threshold=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558f3836-f974-4e36-bd1a-87dc9cecdc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example train function\n",
    "# num_epochs=20\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     x = sequence.permute(0, 2, 1).float().cuda()\n",
    "#     y = target.float().cuda()\n",
    "    \n",
    "#     # forward pass\n",
    "#     pred = model(x)\n",
    "#     print(x.shape, pred.shape)\n",
    "    \n",
    "#     # Compute loss\n",
    "#     loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "    \n",
    "#     # Backward pass and optimization\n",
    "#     loss.backward()\n",
    "    \n",
    "#     optimizer.step()\n",
    "\n",
    "    \n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856fa08-4e95-4ded-9791-84827b06d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train loss:0.27690426\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor 0.0030526697580957438 0.003542320188668639 0.0021053281855192276 0.005134597469163311 0.0019901055379286086\n",
      "500\n",
      "train loss:0.058204312\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor 0.0001596501467121537 -0.0001546204409545666 6.227556498842301e-05 0.0003124226539105827 0.001117784036814831\n",
      "1000\n",
      "train loss:0.00029515632\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor -0.003408185860242576 0.004527108244016793 0.0006406482951593019 0.0007513708979533687 0.011119373227336483\n",
      "1500\n",
      "train loss:0.0010260381\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor 0.0033114915808798795 0.002743869797427067 0.005745940827759937 -0.0043194761383138075 0.0027269302207097276\n",
      "2000\n",
      "train loss:0.0012247341\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor 0.00033004674037885714 -0.0033282302994240894 0.004765649715602938 -0.002632274495505231 0.013244089003423925\n",
      "2500\n",
      "train loss:0.0009184549\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor 0.004468767034515042 0.007286819862235727 0.005562013585270048 0.0025491465203971563 0.00892939027384013\n",
      "3000\n",
      "train loss:0.00062832783\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor -0.00026897275001450696 0.007591273379860831 0.00040206313209145954 0.00010189747366631345 -0.0009176693120123111\n",
      "3500\n",
      "train loss:0.00046282363\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor -0.0035333912929045117 0.00032853981897549395 0.003156226656840719 0.0034555270624657443 0.010950900286835763\n",
      "4000\n",
      "train loss:0.00030637675\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor -0.0008768242805270792 0.006338062371977952 -0.0026788714031405433 0.004394637616955214 0.008993373519402763\n",
      "4500\n",
      "train loss:0.0002514632\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor 0.0013534956368438766 -0.008321123827930484 7.782719927005216e-05 -0.0009109172411521714 -0.007895359404797147\n",
      "5000\n",
      "train loss:0.00017139064\n",
      "0.005\n",
      "(114364328, 4)\n",
      "Cor -0.004301455066854187 -0.007289867421742625 -0.00234007223124806 0.00264423823601202 -0.007110963839970476\n",
      "5500\n",
      "train loss:0.00013273681\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor 0.003162733007242665 0.009311887184559726 -0.006674850248340433 0.00507546501390511 -0.002787366701534873\n",
      "6000\n",
      "train loss:0.00011059577\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor 0.0022527094663229046 -0.0036250769998289866 -0.0015286955308664138 0.0039011280390042905 -0.008453701546096136\n",
      "6500\n",
      "train loss:0.00010794036\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor 0.005769275620902939 0.004745065799967332 0.0041452819527988734 -0.001010730358476964 0.022346103120089812\n",
      "7000\n",
      "train loss:0.000104247985\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor -0.0002635889809965372 -0.0032631032892217163 0.004687082438632641 0.0070505281088033556 0.012788077317146896\n",
      "7500\n",
      "train loss:0.0005664593\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor -0.0008837807963353326 0.0034701977718541955 0.002482232435524981 0.0007033346642455599 0.0018463224516891178\n",
      "8000\n",
      "train loss:8.408521e-05\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor 0.0016119283404571665 0.004069891350953513 0.0020620278566153803 0.004159115539327951 0.007345529521595887\n",
      "8500\n",
      "train loss:8.0643564e-05\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor 0.0031071821443086726 0.004773511853207213 0.0028050603887170844 0.00582726087920271 0.010400016415596007\n",
      "9000\n",
      "train loss:8.370094e-05\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor 0.004291722795291454 0.005883027001274058 0.0037197742039418937 0.0070500425151229194 0.01466123470613262\n",
      "9500\n",
      "train loss:7.9802674e-05\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor 0.00600320474083388 0.007090676631956502 0.005415419827298033 0.008657688952209298 0.015395099725142218\n",
      "10000\n",
      "train loss:8.2906736e-05\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor 0.007909170734727772 0.00869265236404513 0.006865890980084928 0.010666823922451916 0.019102846230446405\n",
      "10500\n",
      "train loss:8.0178455e-05\n",
      "0.0045000000000000005\n",
      "(114364328, 4)\n",
      "Cor 0.009183228311030486 0.009463136257758874 0.005589700036496878 0.009917662581540438 0.022530790872537558\n",
      "11000\n",
      "train loss:8.2183455e-05\n",
      "0.004050000000000001\n",
      "(114364328, 4)\n",
      "Cor 0.011500454368661282 0.013028821607117555 0.009990167533323796 0.013301589024080459 0.027224772216355324\n",
      "11500\n",
      "train loss:8.354031e-05\n",
      "0.004050000000000001\n",
      "(114364328, 4)\n",
      "Cor 0.013529060390485154 0.015673674779489437 0.011601674697961622 0.014792606744417814 0.03166206525481285\n",
      "12000\n",
      "train loss:8.118513e-05\n",
      "0.004050000000000001\n",
      "(114364328, 4)\n",
      "Cor 0.014253058814211891 0.019646814009744294 0.012804667921731985 0.01668937784772384 0.03497547137538408\n",
      "12500\n",
      "train loss:8.759716e-05\n",
      "0.004050000000000001\n",
      "(114364328, 4)\n",
      "Cor 0.015912562619081045 0.021944647650065735 0.01513830526438462 0.017618276490335226 0.03985825864409039\n",
      "13000\n",
      "train loss:7.8989935e-05\n",
      "0.004050000000000001\n",
      "(114364328, 4)\n",
      "Cor 0.015123198799052023 0.022375191095845463 0.015190012065253085 0.016140739653758687 0.03938502452760985\n",
      "13500\n",
      "train loss:8.220943e-05\n",
      "0.004050000000000001\n",
      "(114364328, 4)\n",
      "Cor 0.016278582184939973 0.02436713437597974 0.01853746714544385 0.013799241778950415 0.04634676390362093\n"
     ]
    }
   ],
   "source": [
    "# Puffin\n",
    "i=0\n",
    "past_losses=[]\n",
    "firstvalid=True\n",
    "bestcor=0\n",
    "n_samples = 0\n",
    "while True:\n",
    "    for sequence, target in train_loader:\n",
    "            if torch.rand(1)<0.5:\n",
    "                sequence = sequence.flip([1,2])\n",
    "                target = target.flip([1,2])\n",
    "\n",
    "            n_samples+=sequence.shape[0]\n",
    "            # x = sequence.permute(0, 2, 1).float().cuda()\n",
    "            x = sequence.float().cuda()\n",
    "            y = target.float().cuda()\n",
    "  \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x).transpose(1, 2)\n",
    "        \n",
    "            # loss = (PseudoPoissonKL(pred, target.cuda()) * weights[None,:,None]).mean() \n",
    "            loss = criterion(pred, y)\n",
    "        \n",
    "            loss.backward()\n",
    "            past_losses.append(loss.detach().cpu().numpy())\n",
    "            \n",
    "            # print(i, loss.item())\n",
    "\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "                       \n",
    "\n",
    "     \n",
    "        \n",
    "            if i % 500 ==0:\n",
    "            # if i % 1 == 0:\n",
    "                print(i)\n",
    "                print(\"train loss:\"+str(np.mean(past_losses[-500:])),flush=True)\n",
    "                scheduler.step(loss) \n",
    "                print(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            # if i % 500 == 0:\n",
    "                torch.save(model, '/work/magroup/wenduoc/benchmark/Puffin/baseline_puffin/'+'CNN_3'+'.checkpoint')\n",
    "                torch.save(optimizer, '/work/magroup/wenduoc/benchmark/Puffin/baseline_puffin/'+'CNN_3'+'.optimizer')\n",
    "\n",
    "            rstate_saved = np.random.get_state()\n",
    "            # if i % 8000 == 0:\n",
    "            if i % 500 == 0:\n",
    "            # if i % 1 == 0:\n",
    "                if firstvalid:\n",
    "                    validseq = noblacklist_genome.get_encoding_from_coords(\"chr10\", 0, 114364328)\n",
    "                    validcage = tfeature.get_feature_data(\"chr10\", 0, 114364328)\n",
    "                    firstvalid = False\n",
    "                model.eval()\n",
    "                print(validseq.shape, flush=True)\n",
    "                with torch.no_grad():\n",
    "                    validpred = np.zeros((10, 114364328))\n",
    "                    # kllosses = []\n",
    "                    for ii in np.arange(0, 114364328, 50000)[:-2]:\n",
    "                        pred = (\n",
    "                            model(\n",
    "                                torch.FloatTensor(validseq[ii : ii + 100000, :][None, :, :])\n",
    "                                # .transpose(1, 2)\n",
    "                                .cuda()\n",
    "                            ).transpose(1, 2)\n",
    "                            .cpu()\n",
    "                            .detach()\n",
    "                            .numpy()\n",
    "                        )\n",
    "                        pred2 = (\n",
    "                            model(\n",
    "                                torch.FloatTensor(validseq[ii : ii + 100000, :][None, ::-1, ::-1].copy())\n",
    "                                # .transpose(1, 2)\n",
    "                                .cuda()\n",
    "                            ).transpose(1, 2)\n",
    "                            .cpu()\n",
    "                            .detach()\n",
    "                            .numpy()[:, ::-1, ::-1]\n",
    "                        )\n",
    "\n",
    "                        validpred[:, ii + 25000 : ii + 75000] = (\n",
    "                            pred[0, :, 25000:75000] * 0.5 + pred2[0, :, 25000:75000] * 0.5\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "                validcor = (\n",
    "                    np.corrcoef(validpred[0, :ii], validcage[0, :ii])[0, 1] * 0.5\n",
    "                    + np.corrcoef(validpred[-1, :ii], validcage[-1, :ii])[0, 1] * 0.5\n",
    "                )\n",
    "                validcor2 = (\n",
    "                    np.corrcoef(validpred[1, :ii], validcage[1, :ii])[0, 1] * 0.5\n",
    "                    + np.corrcoef(validpred[-2, :ii], validcage[-2, :ii])[0, 1] * 0.5\n",
    "                )\n",
    "                validcor3 = (\n",
    "                    np.corrcoef(validpred[2, :ii], validcage[2, :ii])[0, 1] * 0.5\n",
    "                    + np.corrcoef(validpred[-3, :ii], validcage[-3, :ii])[0, 1] * 0.5\n",
    "                )\n",
    "                validcor4 = (\n",
    "                    np.corrcoef(validpred[3, :ii], validcage[3, :ii])[0, 1] * 0.5\n",
    "                    + np.corrcoef(validpred[-4, :ii], validcage[-4, :ii])[0, 1] * 0.5\n",
    "                )\n",
    "                validcor5 = (\n",
    "                    np.corrcoef(validpred[4, :ii], validcage[4, :ii])[0, 1] * 0.5\n",
    "                    + np.corrcoef(validpred[-5, :ii], validcage[-5, :ii])[0, 1] * 0.5\n",
    "                )\n",
    "                print(\"Cor {0} {1} {2} {3} {4}\".format(validcor, validcor2, validcor3, validcor4, validcor5))\n",
    "\n",
    "                model.train()\n",
    "                validsum = validcor + validcor2 + validcor3 + validcor4 + validcor5\n",
    "                if bestcor < validsum:\n",
    "                    bestcor = validsum\n",
    "                    torch.save(model, '/work/magroup/wenduoc/benchmark/Puffin/baseline_puffin/'+'CNN_3'+'.best.checkpoint')\n",
    "                    torch.save(optimizer, '/work/magroup/wenduoc/benchmark/Puffin/baseline_puffin/'+'CNN_3'+'.best.optimizer')\n",
    "            i+=1\n",
    "            del x, y, pred, loss\n",
    "            \n",
    "        \n",
    "            if n_samples > 100000:\n",
    "                print('Done!')\n",
    "                break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684dc5a1-4e9f-43e5-a37c-a1fb7c831d15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
